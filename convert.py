#! /usr/bin/env python3


# paj-fetcher -- Download and convert data from PAJ
# By: Evgeniy Smirnov <rassouljb@gmail.com>
#
# Copyright (C) 2020 Cepremap
# https://git.nomics.world/dbnomics-fetchers/paj-fetcher
#
# paj-fetcher is free software; you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# paj-fetcher is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.


"""Convert data from PAJ to DBnomics data model
(see https://git.nomics.world/dbnomics/dbnomics-data-model/).

Usage:
    {self_filename} <source_dir> <target_dir> [options]

source_dir: path of source directory containing World Bank series generated by
            download.py script
target_dir: path of target directory to write datasets & series in DBnomics format
            => all files will be deleted

Options:
    --debug show debug output, and compute some tests that makes process slower

Read source data from a source directory, write converted data to a target directory.

See also `.gitlab-ci.yml` in which data is committed to a Git repository of converted
 data.
"""

import argparse
import json
import logging
import os
import re
import shutil
import sys
from pathlib import Path
from typing import Sequence

import xlrd
from dbnomics_fetcher_toolbox.arguments import add_arguments_for_convert
from dbnomics_fetcher_toolbox.logging_utils import setup_logging
from dbnomics_fetcher_toolbox.sdmx_v2_0 import DatasetStructure, Attribute, Concept, \
    CodeList, Code, AttachmentLevel, Dimension, Series, Value, Obs, \
    parse_observation_value, NAN, structure_to_dataset_json, series_to_series_json
from dbnomics_json_errors import ErrorsArtifact

PROVIDER_DATA = {
    "code": "paj",
    "name": "Petroleum Association of Japan",
    "region": "Japan",
    "terms_of_use": "",
    "website": "https://www.paj.gr.jp/english/statis/",
}

attributes = {'UNIT': Attribute(concept_id="UNIT", codelist_id="CL_UNIT",
                                attachment_level=AttachmentLevel.SERIES)}
codelists = {"CL_UNIT": CodeList(id="CL_UNIT",
                                 codes=[Code(value="kl",
                                             descriptions={"en": "kiloliter"})],
                                 names={"en": "Unit of measure"}),
             "CL_FREQ": CodeList(id="CL_FREQ",
                                 codes=[
                                     Code(value="M", descriptions={"en": "Monthly"})],
                                 names={"en": "Frequency"}),
             "CL_COUNTRY": CodeList(id="CL_COUNTRY",
                                    codes=[Code(value="AE",
                                                descriptions={
                                                    "en": "United Arab Emirates"}),
                                           Code(value="AU",
                                                descriptions={"en": "Australia"}),
                                           Code(value="BH",
                                                descriptions={"en": "Bahrain"}),
                                           Code(value="CH",
                                                descriptions={"en": "China"}),
                                           Code(value="DZ",
                                                descriptions={"en": "Algeria"}),
                                           Code(value="EG",
                                                descriptions={"en": "Egypt"}),
                                           Code(value="ES",
                                                descriptions={"en": "Spain"}),
                                           Code(value="GA",
                                                descriptions={"en": "Gabon"}),
                                           Code(value="GR",
                                                descriptions={"en": "Greece"}),
                                           Code(value="HK",
                                                descriptions={"en": "HongKong"}),
                                           Code(value="ID",
                                                descriptions={"en": "Indonesia"}),
                                           Code(value="IN",
                                                descriptions={"en": "India"}),
                                           Code(value="KR",
                                                descriptions={"en": "South Korea"}),
                                           Code(value="KW",
                                                descriptions={"en": "Kuwait"}),
                                           Code(value="LK",
                                                descriptions={"en": "Sri Lanka"}),
                                           Code(value="MX",
                                                descriptions={"en": "Mexico"}),
                                           Code(value="MY",
                                                descriptions={"en": "Malaysia"}),
                                           Code(value="NO",
                                                descriptions={"en": "Norway"}),
                                           Code(value="PE",
                                                descriptions={"en": "Peru"}),
                                           Code(value="PG",
                                                descriptions={
                                                    "en": "Papua New Guinea"}),
                                           Code(value="PK",
                                                descriptions={"en": "Pakistan"}),
                                           Code(value="PL",
                                                descriptions={"en": "Poland"}),
                                           Code(value="QA",
                                                descriptions={"en": "Qatar"}),
                                           Code(value="RU",
                                                descriptions={"en": "Russia"}),
                                           Code(value="SA",
                                                descriptions={"en": "Saudi Arabia"}),
                                           Code(value="SG",
                                                descriptions={"en": "Singapore"}),
                                           Code(value="TH",
                                                descriptions={"en": "Thailand"}),
                                           Code(value="TW",
                                                descriptions={"en": "Taiwan"}),
                                           Code(value="VN",
                                                descriptions={"en": "Vietnam"}),
                                           Code(value="US",
                                                descriptions={
                                                    "en": "United States of America"}),
                                           Code(value="UNK",
                                                descriptions={"en": "Unknown"})],
                                    names={"en": "Country"}),
             "CL_PRODUCT": CodeList(id="CL_PRODUCT",
                                    codes=[Code(value="FOA",
                                                descriptions={"en": "Fuel Oil A"}),
                                           Code(value="FOBC",
                                                descriptions={"en": "Fuel Oil B-C"}),
                                           Code(value="G",
                                                descriptions={"en": "Gasoline"}),
                                           Code(value="GO",
                                                descriptions={"en": "Gas Oil"}),
                                           Code(value="K",
                                                descriptions={"en": "Kerosene"}),
                                           Code(value="N",
                                                descriptions={"en": "Naphtha"})],
                                    names={"en": "Product"})}
concepts = {"UNIT": Concept(id="UNIT", names={"en": "Unit of measure"}),
            "FREQ": Concept(id="FREQ", names={"en": "Frequency"}),
            "COUNTRY": Concept(id="COUNTRY", names={"en": "Country"}),
            "PRODUCT": Concept(id="PRODUCT", names={"en": "Product"})}

DATASETS_DEFINITIONS = {
    "01": DatasetStructure(
        attributes=[attributes['UNIT']],
        codelists=[codelists["CL_UNIT"],
                   codelists["CL_FREQ"],
                   CodeList(id="CL_INDEX",
                            codes=[Code(value="P", descriptions={"en": "Production"}),
                                   Code(value="I", descriptions={"en": "Import"}),
                                   Code(value="NRU",
                                        descriptions={"en": "non-Refining use"}),
                                   Code(value="RT",
                                        descriptions={"en": "Refinery throughput"}),
                                   Code(value="BD", descriptions={"en": "(b/ï½„)"}),
                                   Code(value="RC",
                                        descriptions={"en": "Refining capacity"}),
                                   Code(value="U", descriptions={"en": "Utilization"}),
                                   Code(value="ES", descriptions={"en": "End stocks"})],
                            names={"en": "Measurement index"})
                   ],
        concepts=[concepts["UNIT"],
                  concepts["FREQ"],
                  Concept(id="INDEX", names={"en": "Index of measurements"})],
        dimensions=[Dimension(concept_id="FREQ", codelist_id="CL_FREQ"),
                    Dimension(concept_id="INDEX", codelist_id="CL_INDEX")],
        id="SDCO",
        names={"en": "Supply and Demand of Crude Oil"}
    ),
    "03": DatasetStructure(
        attributes=[attributes['UNIT']],
        codelists=[codelists["CL_UNIT"],
                   codelists["CL_FREQ"],
                   codelists["CL_COUNTRY"],
                   codelists["CL_PRODUCT"]],
        concepts=[concepts["UNIT"],
                  concepts["FREQ"],
                  concepts["COUNTRY"],
                  concepts["PRODUCT"]],
        dimensions=[Dimension(concept_id="FREQ", codelist_id="CL_FREQ"),
                    Dimension(concept_id="PRODUCT", codelist_id="CL_PRODUCT"),
                    Dimension(concept_id="COUNTRY", codelist_id="CL_COUNTRY")],
        id="PIbC",
        names={"en": "Product Import by Countries"}
    ),
    "05": DatasetStructure(
        attributes=[attributes['UNIT']],
        codelists=[codelists["CL_UNIT"],
                   codelists["CL_FREQ"],
                   codelists["CL_COUNTRY"]],
        concepts=[concepts["UNIT"],
                  concepts["FREQ"],
                  concepts["COUNTRY"]],
        dimensions=[Dimension(concept_id="FREQ", codelist_id="CL_FREQ"),
                    Dimension(concept_id="COUNTRY", codelist_id="CL_COUNTRY")],
        id="COSbS",
        names={"en": "Crude Oil Shipment by Source (non-Refining Use)"}
    ),
}

REGEXS = {
    'period_monthly': r'^(\d{4})\.(\d{2})$',
    'period_only_month': r'^(\d{2})$',
}

log = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--log', default='WARNING', help='level of logging messages')
    add_arguments_for_convert(parser)
    args = parser.parse_args()

    setup_logging(args)

    source_dir = args.source_dir
    if not source_dir.exists():
        parser.error("Source input_dir {!r} not found".format(str(source_dir)))

    target_dir = args.target_dir
    if not target_dir.exists():
        parser.error("Target input_dir {!r} not found".format(str(target_dir)))

    nb_expected_datasets = 0
    errors_artifact = ErrorsArtifact()
    for dir, datasetStructure in DATASETS_DEFINITIONS.items():
        nb_expected_datasets += 1
        dataset_code = datasetStructure.id
        dataset_dir = target_dir / dataset_code
        try:
            convert_dataset(source_dir / dir, datasetStructure, dataset_dir)
        except Exception as e:
            if getattr(args, 'stop-on-exceptions', None):
                raise e
            log.warning("{!r} dataset aborted ! - {}".format(dataset_code, e))
            # Add error to artifacts
            errors_artifact.add_dataset_error(dataset_code, e)
            # Delete dataset input_dir
            shutil.rmtree(dataset_dir)
            continue

    # provider.json
    write_json_file(target_dir / 'provider.json', PROVIDER_DATA)

    return 0


def convert_dataset(input_dir: Path, structure: DatasetStructure, output_dir: Path):
    output_dir.mkdir(exist_ok=True, parents=True)
    dataset_source_xls = \
        sorted(input_dir.glob("*"), key=os.path.basename, reverse=True)[0]
    dataset_source = xlrd.open_workbook(dataset_source_xls, on_demand=True)
    series_dict = None
    if structure.id == 'SDCO':
        source_sheet = dataset_source.sheet_by_index(0)
        index_codes = structure.get_codelist('CL_INDEX').codes
        series_dict = {'M.' + c.value: Series(key=[
            Value(concept_id='FREQ', value='M'),
            Value(concept_id='INDEX', value=c.value),
        ], attributes=[Value(concept_id='UNIT', value='kl')], observations=[])
            for c in index_codes}
        for r_index, cell in enumerate(source_sheet.col(0)):
            match = re.match(REGEXS['period_monthly'], cell.value)
            if match:
                obs_time = match.group(1) + '-' + match.group(2)
                for c_index, index_code in enumerate(index_codes):
                    obs = Obs(time=obs_time, attributes=[],
                              value=parse_observation_value(
                                  source_sheet.cell(r_index, c_index + 1).value or NAN))
                    series_dict['M.' + index_code.value].observations.append(obs)
    elif structure.id == 'PIbC':
        series_dict = {}
        mapping = [{'PRODUCT': 'G',
                    'COUNTRY': {1: 'KR', 2: 'CH', 4: 'SG', 6: 'AE', 7: 'PL', 8: 'US'}},
                   {'PRODUCT': 'N',
                    'COUNTRY': {1: 'KR', 2: 'TW', 3: 'HK', 5: 'TH', 6: 'SG', 7: 'MY',
                                8: 'ID', 10: 'IN', 11: 'PK', 12: 'LK', 14: 'BH',
                                15: 'SA', 16: 'KW', 17: 'QA', 18: 'AE', 20: 'NO',
                                21: 'ES', 22: 'RU', 23: 'GR', 25: 'US', 26: 'MX',
                                27: 'PE', 29: 'DZ', 30: 'EG', 32: 'AU', 33: 'PG'}},
                   {'PRODUCT': 'K',
                    'COUNTRY': {1: 'KR', 2: 'CH', 4: 'MY'}},
                   {'PRODUCT': 'GO',
                    'COUNTRY': {1: 'KR'}},
                   {'PRODUCT': 'FOA',
                    'COUNTRY': {1: 'KR'}},
                   {'PRODUCT': 'FOBC',
                    'COUNTRY': {1: 'KR', 2: 'TW', 4: 'SG', 5: 'MY', 7: 'RU', 8: 'PG'}}]
        for sheet_index, spec in enumerate(mapping):
            source_sheet = dataset_source.sheet_by_index(sheet_index)
            curr_year = None
            series_key = 'M.%s.' % spec['PRODUCT']
            for r_index, cell in enumerate(source_sheet.col(0)):
                match = re.match(REGEXS['period_monthly'], cell.value)
                match_month = re.match(REGEXS['period_only_month'], cell.value)
                if match or match_month:
                    month = match.group(2) if match else match_month.group(1)
                    if match:
                        curr_year = match.group(1)
                    obs_time = curr_year + '-' + month
                    for c_index, country_code in spec['COUNTRY'].items():
                        country_key = series_key + country_code
                        if not series_dict.get(country_key, None):
                            series_dict[country_key] = Series(key=[
                                Value(concept_id='FREQ', value='M'),
                                Value(concept_id='PRODUCT', value=spec['PRODUCT']),
                                Value(concept_id='COUNTRY', value=country_code)
                            ], attributes=[Value(concept_id='UNIT', value='kl')],
                                observations=[])
                        cell_val = source_sheet.cell(r_index, c_index).value
                        cell_val = NAN if cell_val == '-' or not cell_val else cell_val
                        obs = Obs(time=obs_time, attributes=[],
                                  value=parse_observation_value(cell_val))
                        series_dict[country_key].observations.append(obs)
                elif curr_year:
                    break
    elif structure.id == 'COSbS':
        series_dict = {}
        mapping = {2: 'VN', 3: 'ID', 5: 'SA', 6: 'AE', 10: 'GA', 11: 'UNK'}
        source_sheet = dataset_source.sheet_by_index(0)
        curr_year = None
        for r_index, cell in enumerate(source_sheet.col(1)):
            match = re.match(REGEXS['period_monthly'], cell.value)
            match_month = re.match(REGEXS['period_only_month'], cell.value)
            if match or match_month:
                month = match.group(2) if match else match_month.group(1)
                if match:
                    curr_year = match.group(1)
                obs_time = curr_year + '-' + month
                for c_index, country_code in mapping.items():
                    series_key = 'M.' + country_code
                    if not series_dict.get(series_key, None):
                        series_dict[series_key] = Series(key=[
                            Value(concept_id='FREQ', value='M'),
                            Value(concept_id='COUNTRY', value=country_code)
                        ], attributes=[Value(concept_id='UNIT', value='kl')],
                            observations=[])
                    cell_val = source_sheet.cell(r_index, c_index).value
                    cell_val = NAN if cell_val == '-' or not cell_val else cell_val
                    obs = Obs(time=obs_time, attributes=[],
                              value=parse_observation_value(cell_val))
                    series_dict[series_key].observations.append(obs)
            elif curr_year:
                break

    if series_dict:
        write_json_file(output_dir / 'dataset.json',
                        {**structure_to_dataset_json(dataset_code=structure.id,
                                                     structure=structure,
                                                     lang_candidates=["en"],
                                                     all_series=list(
                                                         series_dict.values())),
                         'updated_at': dataset_source_xls.name.split('_')[0]})
        write_jsonl_file(output_dir / 'series.jsonl',
                         [series_to_series_json(s) for s in series_dict.values()])


def write_json_file(file_path: Path, data):
    """Writes data the JSON way to file_path"""

    with file_path.open('w', encoding='utf-8') as json_fd:
        json.dump(data, json_fd, ensure_ascii=False, indent=2, sort_keys=True)


def write_jsonl_file(file_path: Path, data: Sequence):
    """Writes data the JSON way to file_path"""

    with file_path.open('w', encoding='utf-8') as json_fd:
        for entry in data:
            json.dump(entry, json_fd, ensure_ascii=False, sort_keys=True)
            json_fd.write('\n')


if __name__ == '__main__':
    sys.exit(main())
